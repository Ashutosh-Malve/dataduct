#!/usr/bin/env python
# PYTHON_ARGCOMPLETE_OK

"""Script that helps create and validate pipelines from command line
"""
import argparse
from argparse import ArgumentParser
from argparse import RawTextHelpFormatter

from dataduct.config import Config
from dataduct.config import logger_configuration

import logging
logger = logging.getLogger(__name__)

PIPELINE = 'pipeline'
CREATE = 'create'
VALIDATE = 'validate'
ACTIVATE = 'activate'
VISUALIZE = 'visualize'

CONFIG = 'config'
CONFIG_TO_S3 = 'sync_to_s3'
CONFIG_FROM_S3 = 'sync_from_s3'

DATABASE = 'database'
DROP = 'drop'
GRANT = 'grant'
RECREATE = 'recreate'

DEV = 'dev'


def initialize_etl_objects(pipeline_definitions, delay=None,
                           frequency_override=None):
    """Generate etl objects from yaml files
    """
    from dataduct.etl import create_pipeline
    from dataduct.etl import read_pipeline_definition

    etls = []
    for pipeline_definition in pipeline_definitions:
        definition = read_pipeline_definition(pipeline_definition)
        if delay is not None:
            definition.update({'delay': delay})
        if frequency_override is not None:
            definition.update({'frequency': frequency_override})
        etls.append(create_pipeline(definition))
    return etls


def config_actions(action, filename=None, **kwargs):
    """Config related actions are executed in this block
    """
    from dataduct.config.config_actions import sync_to_s3
    from dataduct.config.config_actions import sync_from_s3

    if action == CONFIG_TO_S3:
        return sync_to_s3()
    return sync_from_s3(filename)


def pipeline_actions(action, pipeline_definitions, force=None, delay=None,
                     frequency_override=None, activities_only=None,
                     filename=None, **kwargs):
    """Pipeline related actions are executed in this block
    """
    from dataduct.etl import activate_pipeline
    from dataduct.etl import validate_pipeline
    from dataduct.etl import visualize_pipeline

    for etl in initialize_etl_objects(pipeline_definitions, delay,
                                      frequency_override):
        if action in [VALIDATE, ACTIVATE]:
            validate_pipeline(etl, force)
        if action == ACTIVATE:
            activate_pipeline(etl)
        if action == VISUALIZE:
            visualize_pipeline(etl, activities_only, filename)


def database_actions(action, table_definitions, filename=None, **kwargs):
    """Database related actions are executed in this block
    """
    from dataduct.database import Database

    script = None
    database = Database(files=table_definitions)
    if action == CREATE:
        script = database.create_relations_script()
    elif action == DROP:
        script = database.drop_relations_script()
    elif action == GRANT:
        script = database.grant_relations_script()
    elif action == RECREATE:
        script = database.recreate_relations_script()
    elif action == VISUALIZE:
        database.visualize(filename)

    # TODO: Build execution options
    if script:
        print script


class _HelpAction(argparse._HelpAction):
    """HelpAction class used to render a custom help message
    """
    def __call__(self, parser, namespace, values, option_string=None):
        parser.print_help()
        print ''
        # retrieve subparsers from parser
        subparsers_actions = [
            action for action in parser._actions
            if isinstance(action, argparse._SubParsersAction)]

        for subparsers_action in subparsers_actions:
            # get all subparsers and print help
            for choice, subparser in subparsers_action.choices.items():
                print "Command '{}'".format(choice)
                print subparser.format_usage()
        parser.exit()


def main():
    """Main function
    """
    formatter_class = lambda prog: RawTextHelpFormatter(
        prog, max_help_position=50)

    # Help parser for parsing subparsers in help
    help_parser = ArgumentParser(
        description='Run Dataduct commands',
        add_help=False,
        formatter_class=formatter_class,
    )
    help_parser.add_argument(
        '-h',
        '--help',
        action=_HelpAction,
        help='Help message',
    )

    # Mode parser shared across all pipeline subparsers
    mode_help = 'Mode to run the pipeline and config overrides to use'
    mode_parser = ArgumentParser(
        description=mode_help,
        add_help=False,
    )
    mode_parser.add_argument(
        '-m',
        '--mode',
        default=None,
        help=mode_help
    )

    # Options parser shared actions all pipeline run options
    pipeline_run_options = ArgumentParser(
        description='Specify actions related to running the pipelines',
        add_help=False
    )
    pipeline_run_options.add_argument(
        '-f',
        '--force',
        action='store_true',
        default=False,
        help='Indicates that if this pipeline exists, it will be destroyed',
    )
    pipeline_run_options.add_argument(
        '-d',
        '--delay',
        default=0,
        type=int,
        help='Delay the pipeline by x days',
    )

    # Pipeline definitions parser
    pipeline_definition_help = 'Paths of the pipeline definitions'
    pipeline_definition_parser = ArgumentParser(
        description=pipeline_definition_help,
        add_help=False,
    )
    pipeline_definition_parser.add_argument(
        'pipeline_definitions',
        nargs='+',
        help=pipeline_definition_help,
    )

    # Table definitions parser
    table_definition_help = 'Paths of the table definitions'
    table_definition_parser = ArgumentParser(
        description=table_definition_help,
        add_help=False,
    )
    table_definition_parser.add_argument(
        'table_definitions',
        nargs='+',
        help=table_definition_help,
    )

    # Filepath input parser
    filepath_help = 'filepath input for storing output of actions'
    file_parser = ArgumentParser(
        description=filepath_help,
        add_help=False,
    )
    file_parser.add_argument(
        dest='filename',
        help='Filename to store output of commands',
    )

    # Main parser
    parser = ArgumentParser(
        description='Run Dataduct commands',
        add_help=False,
        parents=[help_parser],
        formatter_class=formatter_class,
    )
    subparsers = parser.add_subparsers(
        dest='command',
        help='Actions for various features',
    )

    # Pipeline parser
    pipeline_parser = subparsers.add_parser(
        PIPELINE,
        formatter_class=formatter_class,
        add_help=False,
        parents=[help_parser]
    )
    pipeline_subparsers = pipeline_parser.add_subparsers(
        dest='action',
        help='Pipeline actions',
    )

    # Pipeline subparsers_action
    pipeline_subparsers.add_parser(
        CREATE,
        formatter_class=formatter_class,
        parents=[
            mode_parser,
            pipeline_run_options,
            pipeline_definition_parser,
        ],
        help='Create a pipeline locally',
    )
    pipeline_subparsers.add_parser(
        VALIDATE,
        formatter_class=formatter_class,
        parents=[
            mode_parser,
            pipeline_run_options,
            pipeline_definition_parser,
        ],
        help='Validate a pipeline with AWS without activating',
    )
    pipeline_subparsers.add_parser(
        ACTIVATE,
        formatter_class=formatter_class,
        parents=[
            mode_parser,
            pipeline_run_options,
            pipeline_definition_parser,
        ],
        help='Activate the pipeline on AWS',
    )
    pipeline_subparsers.add_parser(
        VISUALIZE,
        formatter_class=formatter_class,
        parents=[
            mode_parser,
            file_parser,
            pipeline_definition_parser,
        ],
        help='Visualize the pipeline',
    )

    # Config parser
    config_parser = subparsers.add_parser(
        CONFIG,
        formatter_class=formatter_class,
        add_help=False,
        parents=[help_parser]
    )
    config_subparsers = config_parser.add_subparsers(
        dest='action',
        help='config actions',
    )

    # config subparsers_action
    config_subparsers.add_parser(
        CONFIG_TO_S3,
        formatter_class=formatter_class,
        parents=[
            mode_parser,
        ],
        help='sync config file from local to s3',
    )
    config_subparsers.add_parser(
        CONFIG_FROM_S3,
        formatter_class=formatter_class,
        parents=[
            mode_parser,
            file_parser,
        ],
        help='sync config file from s3 to local file',
    )

    # Database parser
    database_parser = subparsers.add_parser(
        DATABASE,
        formatter_class=formatter_class,
        add_help=False,
        parents=[help_parser]
    )
    database_subparsers = database_parser.add_subparsers(
        dest='action',
        help='database actions',
    )

    # database subparsers_action
    database_subparsers.add_parser(
        CREATE,
        formatter_class=formatter_class,
        parents=[
            mode_parser,
            table_definition_parser,
        ],
        help='Create tables',
    )
    database_subparsers.add_parser(
        DROP,
        formatter_class=formatter_class,
        parents=[
            mode_parser,
            table_definition_parser,
        ],
        help='Drop views and tables',
    )
    database_subparsers.add_parser(
        GRANT,
        formatter_class=formatter_class,
        parents=[
            mode_parser,
            table_definition_parser,
        ],
        help='Grant permissions to neccessary groups',
    )
    database_subparsers.add_parser(
        RECREATE,
        formatter_class=formatter_class,
        parents=[
            mode_parser,
            table_definition_parser,
        ],
        help='Recreate tables, load new data, drop old tables',
    )
    database_subparsers.add_parser(
        VISUALIZE,
        formatter_class=formatter_class,
        parents=[
            mode_parser,
            file_parser,
            table_definition_parser,
        ],
        help='Visualize the database er-diagram',
    )

    # Check if autocomplete is possible
    try:
        import argcomplete
        argcomplete.autocomplete(parser)
    except ImportError:
        pass
    args = parser.parse_args()

    # Check if mode is dev
    mode = args.mode
    if mode is not None:
        # We assume mode:dev = mode:None
        if mode == DEV:
            mode = None

    # To instantiate the singleton object with the correct state
    # As this is the single entry point to the library
    # We can use the __new__ function to set the debug_level
    config = Config(mode=mode)

    # Setup up logging for package
    logger_configuration()

    if mode is not None:
        logger.warning('Running the pipeline in %s mode.' % config.mode)

    # Frequency override
    # Certain modes in the config can override frequency of a pipeline
    frequency_override = config.etl.get('FREQUENCY_OVERRIDE', None)

    arg_vars = vars(args)

    # Action parse
    if args.command == CONFIG:
        config_actions(**arg_vars)
    elif args.command == PIPELINE:
        pipeline_actions(frequency_override=frequency_override, **arg_vars)
    elif args.command == DATABASE:
        database_actions(**arg_vars)
    else:
        raise ValueError('Unknown argument provided, use dataduct')


if __name__ == '__main__':
    main()
